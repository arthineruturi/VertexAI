{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "AafyF9b4WCzWQ3SZOssTGLAf",
      "metadata": {
        "tags": [],
        "id": "AafyF9b4WCzWQ3SZOssTGLAf"
      },
      "source": [
        "1. Install the Vertex AI SDK: Open a terminal window and enter the command below. You can also [install it in a virtualenv](https://googleapis.dev/python/aiplatform/latest/index.html)"
      ]
    },
    {
      "cell_type": "code",
      "id": "HX1z1wfz4N0E1rL5le5ohZdN",
      "metadata": {
        "tags": [],
        "id": "HX1z1wfz4N0E1rL5le5ohZdN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 844
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1719992709235,
          "user_tz": -330,
          "elapsed": 57427,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "62ce37b3-8c40-4419-b125-43834427c171"
      },
      "source": [
        "!pip install --upgrade google-cloud-aiplatform"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-cloud-aiplatform in /usr/local/lib/python3.10/dist-packages (1.56.0)\n",
            "Collecting google-cloud-aiplatform\n",
            "  Downloading google_cloud_aiplatform-1.57.0-py2.py3-none-any.whl (5.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m40.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (2.11.1)\n",
            "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (2.27.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (1.24.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (3.20.3)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (24.1)\n",
            "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (2.8.0)\n",
            "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (3.21.0)\n",
            "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (1.12.3)\n",
            "Requirement already satisfied: shapely<3.0.0dev in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (2.0.4)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (1.10.17)\n",
            "Requirement already satisfied: docstring-parser<1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (0.16)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.63.1)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2.31.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.64.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.48.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (4.9)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.3.3)\n",
            "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.7.1)\n",
            "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.8.2)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /usr/local/lib/python3.10/dist-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform) (0.13.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3->google-cloud-aiplatform) (4.12.2)\n",
            "Requirement already satisfied: numpy<3,>=1.14 in /usr/local/lib/python3.10/dist-packages (from shapely<3.0.0dev->google-cloud-aiplatform) (1.25.2)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (1.5.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (0.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0dev,>=2.7.2->google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2024.6.2)\n",
            "Installing collected packages: google-cloud-aiplatform\n",
            "  Attempting uninstall: google-cloud-aiplatform\n",
            "    Found existing installation: google-cloud-aiplatform 1.56.0\n",
            "    Uninstalling google-cloud-aiplatform-1.56.0:\n",
            "      Successfully uninstalled google-cloud-aiplatform-1.56.0\n",
            "Successfully installed google-cloud-aiplatform-1.57.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "fa30c020f9ad4f038507a16bcf170c0c"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "WH9LFqnDH48Pk7PoZkYZdHIE",
      "metadata": {
        "tags": [],
        "id": "WH9LFqnDH48Pk7PoZkYZdHIE"
      },
      "source": [
        "2. Use the following code in your application to request a model response"
      ]
    },
    {
      "cell_type": "code",
      "id": "OjnriK4MI6VOLkPlXZ1D0u0K",
      "metadata": {
        "tags": [],
        "id": "OjnriK4MI6VOLkPlXZ1D0u0K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1719993225997,
          "user_tz": -330,
          "elapsed": 14627,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "262eb58d-a15e-496c-c622-e04106e1bc79"
      },
      "source": [
        "import base64\n",
        "import vertexai\n",
        "from vertexai.generative_models import GenerativeModel, Part, FinishReason\n",
        "import vertexai.preview.generative_models as generative_models\n",
        "\n",
        "def generate():\n",
        "  vertexai.init(project=\"peaceful-harbor-393817\", location=\"us-east1\")\n",
        "  model = GenerativeModel(\n",
        "    \"gemini-1.5-flash-001\",\n",
        "  )\n",
        "  responses = model.generate_content(\n",
        "      [\"\"\"Multi-choice problem: Define the category of the ticket?\n",
        "Categories:\n",
        "- Credit card\n",
        "- Bank account services\n",
        "- Loans and Mortgages\n",
        "\n",
        "Please only print the category name without anything else.\n",
        "\n",
        "Ticket: I lost my credit card numbered 12345. Can you help with deactivating the card?\n",
        "Category: Credit card\n",
        "\n",
        "Ticket: I would like to change the address associated with my account. I have been calling the bank multiple times but couldn\\'t get through. Please help me.\n",
        "Category: Bank account services\n",
        "\n",
        "Ticket: good morning my name is xxxx xxxx and i appreciate it if you could help me put a stop to chase bank cardmember services. I wrote to chase asking for debt verification and what they sent me a statement which is not acceptable i am asking the bank to validate the debt instead i been receiving mail every month from them attempting to collect a debt i have a right to know this information as a consumer chase account xxxx xxxx xxxx xxxx thanks in advance for your help\n",
        "Category: Loans and Mortgages\n",
        "\n",
        "Ticket: my grand son give me check for i deposit it into my chase account after fund clear my chase bank closed my account never paid me my money they said they need to speak with my grand son check was clear money was taking by my chase bank refuse to pay me my money my grand son called chase times they told him i should call not him to verify the check owner he is out the country most the time date happen check number xxxx claim number is xxxx with chase\n",
        "Category:\n",
        "\"\"\"],\n",
        "      generation_config=generation_config,\n",
        "      safety_settings=safety_settings,\n",
        "  )\n",
        "\n",
        "  print(responses)\n",
        "\n",
        "\n",
        "generation_config = {\n",
        "    \"max_output_tokens\": 256,\n",
        "    \"temperature\": 0.2,\n",
        "    \"top_p\": 0.8,\n",
        "}\n",
        "\n",
        "safety_settings = {\n",
        "    generative_models.HarmCategory.HARM_CATEGORY_HATE_SPEECH: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
        "    generative_models.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
        "    generative_models.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
        "    generative_models.HarmCategory.HARM_CATEGORY_HARASSMENT: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
        "}\n",
        "\n",
        "generate()\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "candidates {\n",
            "  content {\n",
            "    role: \"model\"\n",
            "    parts {\n",
            "      text: \"Bank account services \\n\"\n",
            "    }\n",
            "  }\n",
            "  finish_reason: STOP\n",
            "  safety_ratings {\n",
            "    category: HARM_CATEGORY_HATE_SPEECH\n",
            "    probability: NEGLIGIBLE\n",
            "    probability_score: 0.17981843650341034\n",
            "    severity: HARM_SEVERITY_NEGLIGIBLE\n",
            "    severity_score: 0.09999629855155945\n",
            "  }\n",
            "  safety_ratings {\n",
            "    category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
            "    probability: LOW\n",
            "    probability_score: 0.6363531351089478\n",
            "    severity: HARM_SEVERITY_LOW\n",
            "    severity_score: 0.23792988061904907\n",
            "  }\n",
            "  safety_ratings {\n",
            "    category: HARM_CATEGORY_HARASSMENT\n",
            "    probability: NEGLIGIBLE\n",
            "    probability_score: 0.1139734759926796\n",
            "    severity: HARM_SEVERITY_NEGLIGIBLE\n",
            "    severity_score: 0.12421301752328873\n",
            "  }\n",
            "  safety_ratings {\n",
            "    category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
            "    probability: NEGLIGIBLE\n",
            "    probability_score: 0.1139734759926796\n",
            "    severity: HARM_SEVERITY_NEGLIGIBLE\n",
            "    severity_score: 0.029986508190631866\n",
            "  }\n",
            "}\n",
            "usage_metadata {\n",
            "  prompt_token_count: 311\n",
            "  candidates_token_count: 5\n",
            "  total_token_count: 316\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ],
      "metadata": {
        "id": "oiyZxDM0i5PA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1719993260961,
          "user_tz": -330,
          "elapsed": 8471,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "22156686-7566-4a98-a9af-c9300b063d00"
      },
      "id": "oiyZxDM0i5PA",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-03c33ddd-9947-4094-ba37-73ff8695f649\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-03c33ddd-9947-4094-ba37-73ff8695f649\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving bankingdataset.csv to bankingdataset.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "encoding_list = ['utf-8', 'latin1', 'iso-8859-1', 'cp1252']\n",
        "\n",
        "for encoding in encoding_list:\n",
        "    try:\n",
        "        banking_df = pd.read_csv(\"/content/bankingdataset.csv\", encoding=encoding)\n",
        "        print(f\"Successfully read the file with encoding: {encoding}\")\n",
        "        print(banking_df.head())\n",
        "        break\n",
        "    except UnicodeDecodeError as e:\n",
        "        print(f\"Failed to read the file with encoding: {encoding}. Error: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSJ2A0uflm-r",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1719993270238,
          "user_tz": -330,
          "elapsed": 880,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "83c295d1-9be7-4ca3-be3a-e091ea8745b2"
      },
      "id": "ZSJ2A0uflm-r",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to read the file with encoding: utf-8. Error: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
            "Successfully read the file with encoding: latin1\n",
            "   ÿ\"customer_id\" call_date call_time  \\\n",
            "0      1234567890  31-10-23  13:55:00   \n",
            "1      3456789012  31-10-23  14:05:00   \n",
            "2      1098765432  31-10-23  14:10:00   \n",
            "3      2134567890  31-10-23  14:15:00   \n",
            "4      4567890123  31-10-23  14:20:00   \n",
            "\n",
            "                                     call_transcript  \n",
            "0  Customer: Hello, I'm calling to check on the s...  \n",
            "1  Customer: Hello, I'm calling to inquire about ...  \n",
            "2  Customer: Hello, I'm calling to transfer money...  \n",
            "3  Customer: Hello, I'm calling to dispute a char...  \n",
            "4  Customer: Hello, I'm calling to ask about your...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "# Initialize your Vertex AI model\n",
        "import vertexai\n",
        "from vertexai.generative_models import GenerativeModel\n",
        "\n",
        "vertexai.init(project=\"peaceful-harbor-393817\", location=\"us-east1\")\n",
        "model = GenerativeModel(\"gemini-1.5-flash-001\")\n",
        "\n",
        "# Function to classify the category of a ticket\n",
        "def classify_ticket(call_transcript):\n",
        "    prompt = f\"\"\"Multi-choice problem: Define the category of the ticket?\n",
        "Categories:\n",
        "- Credit card\n",
        "- Bank account services\n",
        "- Loans and Mortgages+\n",
        "\n",
        "Ticket: {call_transcript}\n",
        "Category: \"\"\"\n",
        "    response = model.generate_content(prompt)\n",
        "    return response.text.strip()  # Assuming response has a text attribute\n",
        "\n",
        "\n",
        "# Apply the classification function to each row with rate limiting\n",
        "classifications = []\n",
        "for index, row in banking_df.iterrows():\n",
        "    try:\n",
        "        classification = classify_ticket(row['call_transcript'])\n",
        "        classifications.append(classification)\n",
        "        # print(f\"Processed row {index}: {classification}\")\n",
        "        time.sleep(1)  # Sleep for 1 second to avoid exceeding the quota\n",
        "    except Exception as e:\n",
        "        # print(f\"Error processing row {index}: {e}\")\n",
        "        classifications.append(None)  # Append None if there's an error\n",
        "\n",
        "banking_df[\"Classification\"] = classifications\n",
        "\n",
        "print(banking_df.head())\n"
      ],
      "metadata": {
        "id": "qhFV6boGlqjx"
      },
      "id": "qhFV6boGlqjx",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "name": "Classify help tickets"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}